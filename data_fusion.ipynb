{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd68ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfbad333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicles.VehicleNumber</th>\n",
       "      <th>Vehicles.DamageLevel</th>\n",
       "      <th>Vehicles.ExplosionType</th>\n",
       "      <th>Vehicles.FireType</th>\n",
       "      <th>Vehicles.SerialNumber</th>\n",
       "      <th>Vehicles.Make</th>\n",
       "      <th>Vehicles.Model</th>\n",
       "      <th>Vehicles.NumberOfEngines</th>\n",
       "      <th>Vehicles.RegistrationNumber</th>\n",
       "      <th>Vehicles.FlightOperationType</th>\n",
       "      <th>...</th>\n",
       "      <th>Country</th>\n",
       "      <th>EventDate</th>\n",
       "      <th>State</th>\n",
       "      <th>Agency</th>\n",
       "      <th>EventType</th>\n",
       "      <th>AirportId</th>\n",
       "      <th>AirportName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>TotalInjuryCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11914</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>17276639</td>\n",
       "      <td>cessna</td>\n",
       "      <td>172p</td>\n",
       "      <td>1</td>\n",
       "      <td>n9853l</td>\n",
       "      <td>inst</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2011-10-06 01:30:00</td>\n",
       "      <td>None</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>pgum</td>\n",
       "      <td>guam international airport</td>\n",
       "      <td>13.483611</td>\n",
       "      <td>144.791381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20610</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>on-ground</td>\n",
       "      <td>on-ground</td>\n",
       "      <td>18263383</td>\n",
       "      <td>cessna</td>\n",
       "      <td>182p</td>\n",
       "      <td>1</td>\n",
       "      <td>n9187g</td>\n",
       "      <td>pers</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2004-12-19 10:48:00</td>\n",
       "      <td>ca</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>ful</td>\n",
       "      <td>fullerton municipal airport</td>\n",
       "      <td>33.888053</td>\n",
       "      <td>-118.023612</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>5109</td>\n",
       "      <td>christen industries inc</td>\n",
       "      <td>pitts s</td>\n",
       "      <td>1</td>\n",
       "      <td>n50xv</td>\n",
       "      <td>inst</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2014-08-12 11:52:00</td>\n",
       "      <td>fl</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>27.232221</td>\n",
       "      <td>-82.524169</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18729</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>2235</td>\n",
       "      <td>aviat</td>\n",
       "      <td>a-1b</td>\n",
       "      <td>1</td>\n",
       "      <td>n166ma</td>\n",
       "      <td>pers</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2006-05-26 20:05:00</td>\n",
       "      <td>tx</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28.941667</td>\n",
       "      <td>-96.536941</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>18-8140</td>\n",
       "      <td>piper</td>\n",
       "      <td>pa18</td>\n",
       "      <td>1</td>\n",
       "      <td>n5373y</td>\n",
       "      <td>pers</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2018-08-31 19:00:00</td>\n",
       "      <td>ak</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62.095554</td>\n",
       "      <td>-148.212219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>172s8937</td>\n",
       "      <td>cessna</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>n128rm</td>\n",
       "      <td>inst</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2016-07-18 16:00:00</td>\n",
       "      <td>mo</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>sus</td>\n",
       "      <td>spirit of st louis</td>\n",
       "      <td>38.660278</td>\n",
       "      <td>-90.645835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>12-2288</td>\n",
       "      <td>piper</td>\n",
       "      <td>pa-12</td>\n",
       "      <td>1</td>\n",
       "      <td>n3424m</td>\n",
       "      <td>bant</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2008-08-01 15:46:00</td>\n",
       "      <td>sc</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>cre</td>\n",
       "      <td>grand strand airport</td>\n",
       "      <td>33.811668</td>\n",
       "      <td>-78.723892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>1</td>\n",
       "      <td>substantial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>28-7990479</td>\n",
       "      <td>piper</td>\n",
       "      <td>pa-28-181</td>\n",
       "      <td>1</td>\n",
       "      <td>n2834u</td>\n",
       "      <td>pers</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2007-05-04 20:30:00</td>\n",
       "      <td>nv</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>las</td>\n",
       "      <td>mc carran intl</td>\n",
       "      <td>36.080001</td>\n",
       "      <td>-115.152221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17612</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>23724</td>\n",
       "      <td>boeing</td>\n",
       "      <td>757-24apf</td>\n",
       "      <td>2</td>\n",
       "      <td>n402up</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2007-04-24 07:20:00</td>\n",
       "      <td>ca</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>bur</td>\n",
       "      <td>bob hope airport</td>\n",
       "      <td>34.200553</td>\n",
       "      <td>-118.358612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17014</th>\n",
       "      <td>1</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>32-7200030</td>\n",
       "      <td>piper</td>\n",
       "      <td>pa-32-260</td>\n",
       "      <td>1</td>\n",
       "      <td>n5067t</td>\n",
       "      <td>pers</td>\n",
       "      <td>...</td>\n",
       "      <td>usa</td>\n",
       "      <td>2007-08-25 14:15:00</td>\n",
       "      <td>ny</td>\n",
       "      <td>ntsb</td>\n",
       "      <td>acc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>-72.583335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vehicles.VehicleNumber Vehicles.DamageLevel Vehicles.ExplosionType  \\\n",
       "11914                       1          substantial                   none   \n",
       "20610                       1          substantial              on-ground   \n",
       "8973                        1          substantial                   none   \n",
       "18729                       1          substantial                   none   \n",
       "4934                        1          substantial                   none   \n",
       "7111                        1          substantial                   none   \n",
       "15775                       1          substantial                   none   \n",
       "17558                       1          substantial                    NaN   \n",
       "17612                       1                 none                   none   \n",
       "17014                       1            destroyed                unknown   \n",
       "\n",
       "      Vehicles.FireType Vehicles.SerialNumber            Vehicles.Make  \\\n",
       "11914              none              17276639                   cessna   \n",
       "20610         on-ground              18263383                   cessna   \n",
       "8973               none                  5109  christen industries inc   \n",
       "18729              none                  2235                    aviat   \n",
       "4934               none               18-8140                    piper   \n",
       "7111               none              172s8937                   cessna   \n",
       "15775              none               12-2288                    piper   \n",
       "17558              none            28-7990479                    piper   \n",
       "17612              none                 23724                   boeing   \n",
       "17014           unknown            32-7200030                    piper   \n",
       "\n",
       "      Vehicles.Model  Vehicles.NumberOfEngines Vehicles.RegistrationNumber  \\\n",
       "11914           172p                         1                      n9853l   \n",
       "20610           182p                         1                      n9187g   \n",
       "8973         pitts s                         1                       n50xv   \n",
       "18729           a-1b                         1                      n166ma   \n",
       "4934            pa18                         1                      n5373y   \n",
       "7111             172                         1                      n128rm   \n",
       "15775          pa-12                         1                      n3424m   \n",
       "17558      pa-28-181                         1                      n2834u   \n",
       "17612      757-24apf                         2                      n402up   \n",
       "17014      pa-32-260                         1                      n5067t   \n",
       "\n",
       "      Vehicles.FlightOperationType  ... Country           EventDate  State  \\\n",
       "11914                         inst  ...     usa 2011-10-06 01:30:00   None   \n",
       "20610                         pers  ...     usa 2004-12-19 10:48:00     ca   \n",
       "8973                          inst  ...     usa 2014-08-12 11:52:00     fl   \n",
       "18729                         pers  ...     usa 2006-05-26 20:05:00     tx   \n",
       "4934                          pers  ...     usa 2018-08-31 19:00:00     ak   \n",
       "7111                          inst  ...     usa 2016-07-18 16:00:00     mo   \n",
       "15775                         bant  ...     usa 2008-08-01 15:46:00     sc   \n",
       "17558                         pers  ...     usa 2007-05-04 20:30:00     nv   \n",
       "17612                         None  ...     usa 2007-04-24 07:20:00     ca   \n",
       "17014                         pers  ...     usa 2007-08-25 14:15:00     ny   \n",
       "\n",
       "      Agency EventType AirportId                  AirportName   Latitude  \\\n",
       "11914   ntsb       acc      pgum   guam international airport  13.483611   \n",
       "20610   ntsb       acc       ful  fullerton municipal airport  33.888053   \n",
       "8973    ntsb       acc      None                         None  27.232221   \n",
       "18729   ntsb       acc      None                         None  28.941667   \n",
       "4934    ntsb       acc      None                         None  62.095554   \n",
       "7111    ntsb       acc       sus           spirit of st louis  38.660278   \n",
       "15775   ntsb       acc       cre         grand strand airport  33.811668   \n",
       "17558   ntsb       acc       las               mc carran intl  36.080001   \n",
       "17612   ntsb       acc       bur             bob hope airport  34.200553   \n",
       "17014   ntsb       acc      None                         None  40.700000   \n",
       "\n",
       "        Longitude TotalInjuryCount  \n",
       "11914  144.791381                0  \n",
       "20610 -118.023612                2  \n",
       "8973   -82.524169                2  \n",
       "18729  -96.536941                2  \n",
       "4934  -148.212219                0  \n",
       "7111   -90.645835                0  \n",
       "15775  -78.723892                1  \n",
       "17558 -115.152221                1  \n",
       "17612 -118.358612                1  \n",
       "17014  -72.583335                1  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data_sources/filtered/ntsb.pkl\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4057d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_indices count (40%): 9361\n",
      "Number of NaNs assigned (should be 20% of n): 4680\n",
      "Total NaNs in 'ID' column: 4680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11914       g. i. a.\n",
       "20610       f. m. a.\n",
       "8973            None\n",
       "18729           None\n",
       "4934            None\n",
       "7111     s. o. s. l.\n",
       "15775       g. s. a.\n",
       "17558       m. c. i.\n",
       "17612       b. h. a.\n",
       "17014           None\n",
       "Name: AirportName, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntsb_copied = df.copy()\n",
    "ntsb_copied = ntsb_copied.rename(columns={\"EventDate\": \"Date\", \"NtsbNumber\": \"ID\", \"State\": \"Location\"}) # for schema matching \n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "n = len(ntsb_copied)\n",
    "\n",
    "# select 40% indices for later use\n",
    "n_forty = int(np.floor(0.4 * n))\n",
    "random_indices = np.random.choice(ntsb_copied.index, n_forty, replace=False)\n",
    "print(f\"random_indices count (40%): {len(random_indices)}\")  # Should be ~0.4 * n\n",
    "\n",
    "# select half of these indices to assign NaN in 'ID'\n",
    "n_missing = int(np.floor(0.5 * n_forty))\n",
    "missing_indices = np.random.choice(random_indices, n_missing, replace=False)\n",
    "\n",
    "# assign NaN only to these missing_indices\n",
    "ntsb_copied.loc[missing_indices, \"ID\"] = np.nan  # for slot filling\n",
    "\n",
    "print(f\"Number of NaNs assigned (should be 20% of n): {len(missing_indices)}\")\n",
    "\n",
    "# count total NaNs in 'ID' (including existing NaNs)\n",
    "total_nans = ntsb_copied['ID'].isna().sum()\n",
    "print(f\"Total NaNs in 'ID' column: {total_nans}\")\n",
    "\n",
    "conflict_indices = np.setdiff1d(random_indices, missing_indices)\n",
    "\n",
    "# transform strings for conflict resolution\n",
    "for index, row in ntsb_copied.iterrows():\n",
    "    airport = row[\"AirportName\"]\n",
    "    if pd.notna(airport):\n",
    "        result = ' '.join([word[0] + '.' for word in airport.split()])\n",
    "        ntsb_copied.loc[index, \"AirportName\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f60e6e",
   "metadata": {},
   "source": [
    "## Weather Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f0cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 20858 of 23403 accidents (89.1%)\n",
      "\n",
      "Time difference (min) for matched rows:\n",
      "count    20858.00\n",
      "mean        14.80\n",
      "std         10.81\n",
      "min          0.00\n",
      "25%          5.00\n",
      "50%         15.00\n",
      "75%         25.00\n",
      "max         58.00\n",
      "Name: wx_time_diff, dtype: float64\n",
      "\n",
      "Spatial deltas (deg lat/lon) for matched rows:\n",
      "              lat         lon\n",
      "count  20858.0000  20858.0000\n",
      "mean       0.0000      0.0000\n",
      "std        0.0010      0.0010\n",
      "min        0.0000      0.0000\n",
      "25%        0.0000      0.0000\n",
      "50%        0.0000      0.0000\n",
      "75%        0.0000      0.0000\n",
      "max        0.0753      0.0881\n"
     ]
    }
   ],
   "source": [
    "# spatial & temporal thresholds\n",
    "LAT_LON_EPS   = 0.10       # â‰ˆ 11 km at mid-latitudes\n",
    "MAX_TIME_DIFF = pd.Timedelta('3h')   # reject candidates > 3 h away\n",
    "\n",
    "# --- 1. Load data -------------------------------------------------------------\n",
    "ntsb_path    = Path(\"data_sources/filtered/ntsb.pkl\")\n",
    "weather_path = Path(\"data_sources/filtered/weather.pkl\")\n",
    "\n",
    "ntsb    = pd.read_pickle(ntsb_path)\n",
    "weather = pd.read_pickle(weather_path)\n",
    "\n",
    "# ensure correct dtypes\n",
    "ntsb[\"EventDate\"] = pd.to_datetime(ntsb[\"EventDate\"], errors=\"coerce\")\n",
    "weather[\"time\"]   = pd.to_datetime(weather[\"time\"],   errors=\"coerce\")\n",
    "\n",
    "# --- 2. Blocking on event *date* ---------------------------------------------\n",
    "ntsb[\"event_day\"]    = ntsb[\"EventDate\"].dt.date\n",
    "weather[\"weather_day\"] = weather[\"time\"].dt.date\n",
    "\n",
    "weather_by_day = {d: w.reset_index(drop=True)\n",
    "                  for d, w in weather.groupby(\"weather_day\")}\n",
    "\n",
    "# --- 3. Similarity matching & temporal precedence -----------------------------\n",
    "best_rows = []       # stores best-matching weather rows (or None)\n",
    "\n",
    "for _, acc in ntsb.iterrows():\n",
    "    day_candidates = weather_by_day.get(acc[\"event_day\"], pd.DataFrame())\n",
    "    if day_candidates.empty:\n",
    "        best_rows.append(None); continue\n",
    "    \n",
    "    # coarse spatial filter  |lat/lon diff| < LAT_LON_EPS\n",
    "    spatial = day_candidates[\n",
    "        (day_candidates[\"time\"].notna()) &\n",
    "        (day_candidates[\"AccidentID\"].notna()) &       # keeps malformed rows out\n",
    "        (day_candidates[\"AccidentID\"].str.contains('_'))  # quick sanity\n",
    "    ].copy()\n",
    "\n",
    "    spatial = spatial[\n",
    "        (np.abs(spatial[\"AccidentID\"].str.split('_').str[-2].astype(float) - acc[\"Latitude\" ] ) < LAT_LON_EPS) &\n",
    "        (np.abs(spatial[\"AccidentID\"].str.split('_').str[-1].astype(float) - acc[\"Longitude\"]) < LAT_LON_EPS)\n",
    "    ]\n",
    "\n",
    "    if spatial.empty:\n",
    "        best_rows.append(None); continue\n",
    "    \n",
    "    # temporal distance to the accident moment\n",
    "    spatial[\"time_diff\"] = (spatial[\"time\"] - acc[\"EventDate\"]).abs()\n",
    "    \n",
    "    # keep the closest hour that is still within MAX_TIME_DIFF\n",
    "    spatial = spatial[spatial[\"time_diff\"] <= MAX_TIME_DIFF]\n",
    "    \n",
    "    best_rows.append(spatial.nsmallest(1, \"time_diff\").iloc[0] if not spatial.empty else None)\n",
    "\n",
    "# --- 4. Assemble the fused dataset -------------------------------------------\n",
    "weather_match_df = pd.DataFrame.from_records(\n",
    "    [row.to_dict() if row is not None else {}          # convert None into an empty dict {}\n",
    "     for row in best_rows],\n",
    "    index=ntsb.index                                   # keeps row-alignment\n",
    ")\n",
    "\n",
    "accident_weather = pd.concat(\n",
    "    [ntsb.reset_index(drop=True),\n",
    "     weather_match_df.add_prefix(\"wx_\")],              # prefix to avoid clashes\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- 5. Quick diagnostics -----------------------------------------------------\n",
    "total_accidents = len(ntsb)\n",
    "matched         = accident_weather[\"wx_time\"].notna().sum()\n",
    "print(f\"Matched {matched} of {total_accidents} accidents \"\n",
    "      f\"({matched / total_accidents:.1%})\")\n",
    "\n",
    "if matched:\n",
    "    print(\"\\nTime difference (min) for matched rows:\")\n",
    "    print((accident_weather.loc[accident_weather.wx_time.notna(), \"wx_time_diff\"]\n",
    "           .dt.total_seconds().div(60)\n",
    "           .describe().round(2)))\n",
    "\n",
    "    print(\"\\nSpatial deltas (deg lat/lon) for matched rows:\")\n",
    "    lat_delta = np.abs(accident_weather[\"Latitude\"] - accident_weather[\"wx_AccidentID\"]\n",
    "                       .str.split('_').str[-2].astype(float))\n",
    "    lon_delta = np.abs(accident_weather[\"Longitude\"] - accident_weather[\"wx_AccidentID\"]\n",
    "                       .str.split('_').str[-1].astype(float))\n",
    "    print(pd.concat({\"lat\": lat_delta, \"lon\": lon_delta}, axis=1).describe().round(4))\n",
    "\n",
    "accident_weather.drop(columns=[\"event_day\",\"wx_AccidentID\",\"wx_weather_day\"], errors='ignore', inplace=True)\n",
    "accident_weather.to_pickle(\"data_sources/fused/accident_weather.pkl\")\n",
    "accident_weather.to_csv(\"data_sources/fused/accident_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4e03a",
   "metadata": {},
   "source": [
    "## Matched Aircraft Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion complete. Enriched dataset saved to: data_sources/fused/accident_weather_enriched.pkl\n",
      "\n",
      "--- Matching Statistics ---\n",
      "Total records in original dataset: 23403\n",
      "Total records matched with binding CSV: 4962\n",
      "Total unmatched records: 18441\n",
      "Match percentage: 21.20%\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "accident_weather_path = 'data_sources/fused/accident_weather.pkl'\n",
    "matched_results_path = 'data_sources/binding/matched_results.csv'\n",
    "\n",
    "accident_weather_df = pd.read_pickle(accident_weather_path)\n",
    "matched_results_df = pd.read_csv(matched_results_path)\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    \"\"\" Normalizzazione del testo: rimozione di caratteri speciali, lowercase e spazi extra. \"\"\"\n",
    "    return re.sub(r'\\W+', ' ', str(s)).lower().strip()\n",
    "\n",
    "# Pulizia dei dati\n",
    "accident_weather_df['Vehicles.Model'] = accident_weather_df['Vehicles.Model'].apply(clean_text)\n",
    "accident_weather_df['Vehicles.Make'] = accident_weather_df['Vehicles.Make'].apply(clean_text)\n",
    "\n",
    "# Normalize casing for matching\n",
    "matched_results_df['NtsbNumber'] = matched_results_df['NtsbNumber'].str.lower()\n",
    "matched_results_df['EventDate'] = pd.to_datetime(matched_results_df['EventDate'], errors='coerce')\n",
    "matched_results_df['Vehicles.SerialNumber'] = matched_results_df['Vehicles.SerialNumber'].str.lower()\n",
    "matched_results_df['Vehicles.RegistrationNumber'] = matched_results_df['Vehicles.RegistrationNumber'].str.lower()\n",
    "matched_results_df['Vehicles.Make'] = matched_results_df['Vehicles.Make'].str.lower()\n",
    "matched_results_df['Vehicles.Model'] = matched_results_df['Vehicles.Model'].str.lower()\n",
    "\n",
    "matched_results_df.drop(columns=[\"JW_Score\",\"LEV_Score\",\"Jac_Score\",\"SimilarityScore\",\"Matched_Aircraft_Model\"], errors='ignore', inplace=True)\n",
    "\n",
    "\n",
    "accident_weather_df['NtsbNumber'] = accident_weather_df['NtsbNumber'].str.lower()\n",
    "accident_weather_df['EventDate'] = pd.to_datetime(accident_weather_df['EventDate'], errors='coerce')\n",
    "accident_weather_df['Vehicles.SerialNumber'] = accident_weather_df['Vehicles.SerialNumber'].astype(str).str.lower()\n",
    "accident_weather_df['Vehicles.RegistrationNumber'] = accident_weather_df['Vehicles.RegistrationNumber'].astype(str).str.lower()\n",
    "accident_weather_df['Vehicles.Make'] = accident_weather_df['Vehicles.Make'].astype(str).str.lower()\n",
    "accident_weather_df['Vehicles.Model'] = accident_weather_df['Vehicles.Model'].astype(str).str.lower()\n",
    "\n",
    "accident_weather_df.drop(columns=[\"Vehicles.VehicleNumber\"], errors='ignore', inplace=True)\n",
    "accident_weather_df.rename(columns={\"wx_time\": \"weather_time\"}, inplace=True)\n",
    "\n",
    "for key in accident_weather_df.columns:\n",
    "    if key.startswith('wx_'):\n",
    "        accident_weather_df.rename(columns={key: key[3:]}, inplace=True)\n",
    "\n",
    "# Define the merge keys\n",
    "merge_keys = ['NtsbNumber','EventDate','Vehicles.SerialNumber', 'Vehicles.RegistrationNumber', 'Vehicles.Make', 'Vehicles.Model']\n",
    "\n",
    "# Perform the merge\n",
    "fused_df = accident_weather_df.merge(\n",
    "    matched_results_df,\n",
    "    how='left',\n",
    "    left_on=merge_keys,\n",
    "    right_on=merge_keys\n",
    ")\n",
    "\n",
    "# Drop the duplicate matching columns from the right\n",
    "for key in merge_keys:\n",
    "    fused_df.drop(columns=[f\"{key}_y\"], errors='ignore', inplace=True)\n",
    "    fused_df.rename(columns={f\"{key}_x\": key}, inplace=True)\n",
    "\n",
    "# Save the resulting dataframe\n",
    "fused_df.to_pickle('data_sources/fused/accident_weather_enriched.pkl')\n",
    "fused_df.to_csv(\"data_sources/fused/accident_weather_enriched.csv\", index=False)\n",
    "\n",
    "# Compute matching stats\n",
    "total_records = len(accident_weather_df)\n",
    "matched_records = fused_df['Matched_Aircraft_Model'].notna().sum()\n",
    "unmatched_records = total_records - matched_records\n",
    "match_percentage = (matched_records / total_records) * 100\n",
    "\n",
    "# Print statistics\n",
    "print(\"Fusion complete. Enriched dataset saved to: data_sources/fused/accident_weather_enriched.pkl\")\n",
    "print(\"\\n--- Matching Statistics ---\")\n",
    "print(f\"Total records in original dataset: {total_records}\")\n",
    "print(f\"Total records matched with binding CSV: {matched_records}\")\n",
    "print(f\"Total unmatched records: {unmatched_records}\")\n",
    "print(f\"Match percentage: {match_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd24517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23403 entries, 0 to 23402\n",
      "Data columns (total 49 columns):\n",
      " #   Column                        Non-Null Count  Dtype          \n",
      "---  ------                        --------------  -----          \n",
      " 0   Vehicles.DamageLevel          23400 non-null  category       \n",
      " 1   Vehicles.ExplosionType        21880 non-null  category       \n",
      " 2   Vehicles.FireType             23321 non-null  category       \n",
      " 3   Vehicles.SerialNumber         23403 non-null  object         \n",
      " 4   Vehicles.Make                 23403 non-null  object         \n",
      " 5   Vehicles.Model                23403 non-null  object         \n",
      " 6   Vehicles.NumberOfEngines      23403 non-null  int64          \n",
      " 7   Vehicles.RegistrationNumber   23403 non-null  object         \n",
      " 8   Vehicles.FlightOperationType  21593 non-null  object         \n",
      " 9   Vehicles.OperatorName         11290 non-null  object         \n",
      " 10  Oid                           23403 non-null  object         \n",
      " 11  MKey                          23403 non-null  int64          \n",
      " 12  HighestInjury                 23307 non-null  category       \n",
      " 13  NtsbNumber                    23403 non-null  object         \n",
      " 14  ProbableCause                 23205 non-null  object         \n",
      " 15  City                          23403 non-null  object         \n",
      " 16  Country                       23403 non-null  object         \n",
      " 17  EventDate                     23403 non-null  datetime64[ns] \n",
      " 18  State                         23356 non-null  object         \n",
      " 19  Agency                        22495 non-null  object         \n",
      " 20  EventType                     23403 non-null  category       \n",
      " 21  AirportId                     17179 non-null  object         \n",
      " 22  AirportName                   17208 non-null  object         \n",
      " 23  Latitude                      23107 non-null  float64        \n",
      " 24  Longitude                     23106 non-null  float64        \n",
      " 25  TotalInjuryCount              23403 non-null  int64          \n",
      " 26  weather_time                  20858 non-null  datetime64[ns] \n",
      " 27  temperature_2m                20858 non-null  float64        \n",
      " 28  relative_humidity_2m          20858 non-null  float64        \n",
      " 29  dew_point_2m                  20858 non-null  float64        \n",
      " 30  pressure_msl                  20858 non-null  float64        \n",
      " 31  surface_pressure              20858 non-null  float64        \n",
      " 32  precipitation                 20858 non-null  float64        \n",
      " 33  rain                          20858 non-null  float64        \n",
      " 34  snowfall                      20858 non-null  float64        \n",
      " 35  cloud_cover                   20858 non-null  float64        \n",
      " 36  cloud_cover_low               20858 non-null  float64        \n",
      " 37  cloud_cover_mid               20858 non-null  float64        \n",
      " 38  cloud_cover_high              20858 non-null  float64        \n",
      " 39  wind_speed_10m                20858 non-null  float64        \n",
      " 40  wind_speed_100m               20858 non-null  float64        \n",
      " 41  wind_direction_10m            20858 non-null  float64        \n",
      " 42  wind_direction_100m           20858 non-null  float64        \n",
      " 43  wind_gusts_10m                20858 non-null  float64        \n",
      " 44  weather_code                  20858 non-null  float64        \n",
      " 45  snow_depth                    20294 non-null  float64        \n",
      " 46  time_diff                     20858 non-null  timedelta64[ns]\n",
      " 47  engine_count                  4962 non-null   float64        \n",
      " 48  engine_type                   4962 non-null   object         \n",
      "dtypes: category(5), datetime64[ns](2), float64(22), int64(3), object(16), timedelta64[ns](1)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "fused_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49129579",
   "metadata": {},
   "source": [
    "## fixing issue between `engine_count` and `Vehicles.NumberOfEngines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2d9efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fusion complete. Cleaned dataset saved to:\n",
      "  â€¢ data_sources/fused/accident_weather_final.pkl\n",
      "  â€¢ data_sources/fused/accident_weather_final.csv\n",
      "ðŸ”„ 8 engine count conflicts were resolved by trusting the 'engine_count' value.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_path = 'data_sources/fused/accident_weather_enriched.pkl'\n",
    "df = pd.read_pickle(df_path)\n",
    "\n",
    "# Convert columns to nullable integers\n",
    "engine_count_int = df['engine_count'].astype('Int64')\n",
    "vehicle_engines = df['Vehicles.NumberOfEngines'].astype('Int64')\n",
    "\n",
    "# Rule 1: Fill NaNs in Vehicles.NumberOfEngines with engine_count\n",
    "df['Vehicles.NumberOfEngines'] = vehicle_engines.combine_first(engine_count_int)\n",
    "\n",
    "# Rule 2: If Vehicles.NumberOfEngines == 0 and engine_count > 0 â†’ trust engine_count\n",
    "mask_replace_zero = (\n",
    "    (df['Vehicles.NumberOfEngines'] == 0) &\n",
    "    (engine_count_int > 0)\n",
    ")\n",
    "df.loc[mask_replace_zero, 'Vehicles.NumberOfEngines'] = engine_count_int[mask_replace_zero]\n",
    "\n",
    "# Rule 3: Overwrite in case of real conflict (â‰  0 and â‰  each other)\n",
    "conflict_mask = (\n",
    "    engine_count_int.notna() &\n",
    "    df['Vehicles.NumberOfEngines'].notna() &\n",
    "    (df['Vehicles.NumberOfEngines'] != engine_count_int) &\n",
    "    (df['Vehicles.NumberOfEngines'] != 0) &\n",
    "    (engine_count_int != 0)\n",
    ")\n",
    "df.loc[conflict_mask, 'Vehicles.NumberOfEngines'] = engine_count_int[conflict_mask]\n",
    "\n",
    "# Drop auxiliary column\n",
    "df.drop(columns=['engine_count'], inplace=True)\n",
    "\n",
    "# Save cleaned and final dataset\n",
    "final_pkl_path = 'data_sources/fused/accident_weather_final.pkl'\n",
    "final_csv_path = 'data_sources/fused/accident_weather_final.csv'\n",
    "\n",
    "df.to_pickle(final_pkl_path)\n",
    "df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"âœ… Fusion complete. Cleaned dataset saved to:\\n  â€¢ {final_pkl_path}\\n  â€¢ {final_csv_path}\")\n",
    "print(f\"ðŸ”„ {conflict_mask.sum()} engine count conflicts were resolved by trusting the 'engine_count' value.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
