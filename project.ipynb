{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Phase 1 - Aviation Accident Data Integration\n",
    "### Group 03:\n",
    "- Tommaso Tragno - fc64699\n",
    "- Manuel Cardoso - fc56274\n",
    "- Chen Cheng - fc64872\n",
    "- Cristian Tedesco - fc65149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pymongo as pm\n",
    "import mysql.connector\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "1. Load the `.csv` and `.json` dataset;\n",
    "2. Drop the rows that do not contains required data\n",
    "3. Fill the `na` cells with a predefined value\n",
    "4. Drop eventualy doplicates\n",
    "5. Convert the string data into the proper data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check NA values presence before data validation\n",
      "Airline traffic data frame: False\n",
      "NTSB data frame: True\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data_sources'\n",
    "\n",
    "# Load dataset into pandas dataframe\n",
    "df_airline_traffic = pd.read_csv(f'{PATH}/u-s-airline-traffic-data.csv')\n",
    "df_ntsb = pd.read_json(f'{PATH}/ntsb-us-2003-2023.json')\n",
    "\n",
    "print('Check NA values presence before data validation')\n",
    "print(f'Airline traffic data frame: {df_airline_traffic.isna().any().any()}')\n",
    "print(f'NTSB data frame: {df_ntsb.isna().any().any()}')\n",
    "\n",
    "# Convert EventDate to datetime and remove timezone\n",
    "df_ntsb['EventDate'] = pd.to_datetime(df_ntsb['EventDate']).dt.tz_localize(None)\n",
    "\n",
    "#df.drop_duplicates(subset=[col for col in df.columns if df[col].dtype != 'object'], inplace=True) # no need to drop duplicates because there aren't\n",
    "\n",
    "df_ntsb = df_ntsb.map(lambda x: x.lower() if isinstance(x, str) else x) # make all appropriate values lowercase\n",
    "\n",
    "# combines all injury counts to 1 column\n",
    "df_ntsb['TotalInjuryCount'] = df_ntsb[['FatalInjuryCount', 'MinorInjuryCount', 'SeriousInjuryCount']].sum(axis=1)\n",
    "\n",
    "# dropping unnecessary columns\n",
    "df_ntsb.drop(columns=['AnalysisNarrative','FactualNarrative','PrelimNarrative','InvestigationClass','BoardLaunch','BoardMeetingDate','Launch','IsStudy'\n",
    "                 ,'OriginalPublishedDate','DocketOriginalPublishDate','ReportType','ReportNum','ReportDate','MostRecentReportType'\n",
    "                 ,'FatalInjuryCount','MinorInjuryCount','SeriousInjuryCount','DocketDate','Mode','HasSafetyRec','CompletionStatus','Closed'], inplace=True) \n",
    "\n",
    "# dropping NaT entries from EventDate\n",
    "df_ntsb = df_ntsb.dropna(subset=['EventDate'])\n",
    "\n",
    "print(df_ntsb.columns.tolist())\n",
    "#print(df.describe())  # Summary statistics\n",
    "#print(df.info())  # Data types and missing values\n",
    "#print(df.isnull().sum())  # Check missing values\n",
    "\n",
    "df_ntsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to filter to the date we want\n",
    "\n",
    "# Debug: Check min and max dates\n",
    "print(\"Earliest Date:\", df_ntsb['EventDate'].min())\n",
    "print(\"Latest Date:\", df_ntsb['EventDate'].max())\n",
    "\n",
    "# Define the date range (without timezone)\n",
    "start_date = pd.to_datetime('2003-01-01')\n",
    "end_date = pd.to_datetime('2023-12-31')\n",
    "\n",
    "# Filter the dataset\n",
    "filtered_df = df_ntsb[(df_ntsb['EventDate'] >= start_date) & (df_ntsb['EventDate'] <= end_date) & (df_ntsb['Country'] == 'usa')]\n",
    "print(filtered_df['State'].tolist())\n",
    "filtered_df\n",
    "# Display results\n",
    "#print(f\"Total Records Found: {len(filtered_df)}\")\n",
    "#print(filtered_df[['EventDate', 'HighestInjury', 'Country']].sample(10))  # Show 50 random dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open-meteo API call test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 41.581722, 'longitude': -90.64935, 'generationtime_ms': 0.3064870834350586, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 228.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '째C', 'relative_humidity_2m': '%', 'dew_point_2m': '째C', 'pressure_msl': 'hPa', 'surface_pressure': 'hPa', 'precipitation': 'mm', 'rain': 'mm', 'snowfall': 'cm', 'cloud_cover': '%', 'cloud_cover_low': '%', 'cloud_cover_mid': '%', 'cloud_cover_high': '%', 'wind_speed_10m': 'km/h', 'wind_speed_100m': 'km/h', 'wind_direction_10m': '째', 'wind_direction_100m': '째', 'wind_gusts_10m': 'km/h', 'weather_code': 'wmo code', 'snow_depth': 'm'}, 'hourly': {'time': ['2023-12-31T00:00', '2023-12-31T01:00', '2023-12-31T02:00', '2023-12-31T03:00', '2023-12-31T04:00', '2023-12-31T05:00', '2023-12-31T06:00', '2023-12-31T07:00', '2023-12-31T08:00', '2023-12-31T09:00', '2023-12-31T10:00', '2023-12-31T11:00', '2023-12-31T12:00', '2023-12-31T13:00', '2023-12-31T14:00', '2023-12-31T15:00', '2023-12-31T16:00', '2023-12-31T17:00', '2023-12-31T18:00', '2023-12-31T19:00', '2023-12-31T20:00', '2023-12-31T21:00', '2023-12-31T22:00', '2023-12-31T23:00'], 'temperature_2m': [1.1, -0.6, -1.0, -0.4, -1.3, -1.8, -2.2, -2.7, -2.7, -2.9, -3.2, -3.1, -2.9, -2.6, -2.4, -1.6, -0.7, -0.1, 0.6, 1.2, 1.0, 1.1, 0.8, 0.1], 'relative_humidity_2m': [85, 89, 89, 80, 71, 69, 70, 74, 73, 71, 72, 76, 78, 77, 77, 74, 70, 73, 74, 73, 72, 68, 67, 70], 'dew_point_2m': [-1.1, -2.2, -2.6, -3.5, -5.8, -6.7, -6.8, -6.7, -6.9, -7.4, -7.5, -6.8, -6.2, -6.1, -5.8, -5.7, -5.6, -4.4, -3.4, -3.1, -3.5, -4.2, -4.5, -4.8], 'pressure_msl': [1011.4, 1012.5, 1012.8, 1013.3, 1013.5, 1013.9, 1014.2, 1014.0, 1014.1, 1014.6, 1014.6, 1014.8, 1015.1, 1015.8, 1016.1, 1016.6, 1017.3, 1017.7, 1017.8, 1018.2, 1018.8, 1019.7, 1020.8, 1021.8], 'surface_pressure': [983.2, 984.0, 984.3, 984.8, 984.9, 985.3, 985.5, 985.3, 985.4, 985.9, 985.8, 986.0, 986.3, 987.1, 987.4, 987.9, 988.7, 989.2, 989.3, 989.8, 990.3, 991.2, 992.3, 993.2], 'precipitation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0], 'rain': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'snowfall': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21, 0.07, 0.07, 0.0, 0.0, 0.0, 0.0], 'cloud_cover': [100, 87, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 99, 100, 100, 100, 100, 100, 100, 99, 100], 'cloud_cover_low': [0, 46, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 98, 96, 100, 100, 97, 100, 100, 92, 98, 100], 'cloud_cover_mid': [88, 0, 0, 0, 0, 0, 0, 25, 12, 37, 45, 98, 100, 100, 96, 85, 100, 100, 100, 100, 100, 100, 42, 0], 'cloud_cover_high': [100, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 99, 18, 0, 0, 0, 0, 0, 0], 'wind_speed_10m': [12.0, 11.2, 13.2, 16.6, 17.4, 16.7, 15.8, 16.7, 17.8, 18.1, 18.5, 17.7, 17.4, 16.9, 15.9, 16.8, 18.4, 20.4, 22.6, 25.1, 21.5, 20.1, 18.1, 18.0], 'wind_speed_100m': [26.0, 25.5, 27.7, 27.6, 27.5, 26.1, 25.6, 27.9, 28.5, 28.7, 29.3, 27.5, 27.4, 26.7, 24.8, 23.8, 25.5, 28.0, 31.5, 35.4, 30.8, 29.6, 28.6, 30.1], 'wind_direction_10m': [261, 272, 292, 319, 310, 303, 297, 284, 288, 293, 294, 294, 292, 294, 295, 305, 310, 315, 326, 331, 329, 327, 325, 323], 'wind_direction_100m': [266, 279, 300, 320, 312, 305, 299, 287, 291, 297, 298, 297, 295, 297, 300, 308, 312, 315, 327, 332, 330, 328, 326, 326], 'wind_gusts_10m': [19.1, 19.1, 21.2, 26.6, 29.2, 28.8, 28.1, 27.4, 29.9, 30.2, 31.0, 31.7, 29.5, 28.8, 27.7, 29.2, 32.8, 33.8, 39.6, 44.3, 43.2, 37.1, 33.5, 29.5], 'weather_code': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 73, 71, 71, 3, 3, 3, 3], 'snow_depth': [0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]}}\n",
      "Weather data at 2023-12-31T17:00Z:\n",
      "temperature_2m: -0.1\n",
      "relative_humidity_2m: 73\n",
      "dew_point_2m: -4.4\n",
      "pressure_msl: 1017.7\n",
      "surface_pressure: 989.2\n",
      "precipitation: 0.3\n",
      "rain: 0.0\n",
      "snowfall: 0.21\n",
      "cloud_cover: 100\n",
      "cloud_cover_low: 100\n",
      "cloud_cover_mid: 100\n",
      "cloud_cover_high: 18\n",
      "wind_speed_10m: 20.4\n",
      "wind_speed_100m: 28.0\n",
      "wind_direction_10m: 315\n",
      "wind_direction_100m: 315\n",
      "wind_gusts_10m: 33.8\n",
      "weather_code: 73\n",
      "snow_depth: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Define the endpoint\n",
    "endpoint = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    \"latitude\": 41.610278,\n",
    "    \"longitude\": -90.588361,\n",
    "    \"start_date\": \"2023-12-31\",\n",
    "    \"end_date\": \"2023-12-31\",\n",
    "    \"hourly\": \",\".join([\n",
    "        \"temperature_2m\",\n",
    "        \"relative_humidity_2m\",\n",
    "        \"dew_point_2m\",\n",
    "        \"pressure_msl\",\n",
    "        \"surface_pressure\",\n",
    "        \"precipitation\",\n",
    "        \"rain\",\n",
    "        \"snowfall\",\n",
    "        \"cloud_cover\",\n",
    "        \"cloud_cover_low\",\n",
    "        \"cloud_cover_mid\",\n",
    "        \"cloud_cover_high\",\n",
    "        \"wind_speed_10m\",\n",
    "        \"wind_speed_100m\",\n",
    "        \"wind_direction_10m\",\n",
    "        \"wind_direction_100m\",\n",
    "        \"wind_gusts_10m\",\n",
    "        \"weather_code\",\n",
    "        \"snow_depth\"\n",
    "    ]),\n",
    "    \"timezone\": \"GMT\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(endpoint, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Process the data as needed\n",
    "    print(data)\n",
    "    time_series = data[\"hourly\"][\"time\"]\n",
    "    try:\n",
    "        idx = time_series.index(\"2023-12-31T17:00\")\n",
    "        selected_data = {k: v[idx] for k, v in data[\"hourly\"].items() if k != \"time\"}\n",
    "        print(f\"Weather data at 2023-12-31T17:00Z:\")\n",
    "        for key, val in selected_data.items():\n",
    "            print(f\"{key}: {val}\")\n",
    "    except ValueError:\n",
    "        print(\"Selected hour not found in response.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
